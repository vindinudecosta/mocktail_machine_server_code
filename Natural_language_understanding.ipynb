{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vindinudecosta/mocktail_machine_server_code/blob/main/Natural_language_understanding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfl8mU_76rhD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmbUdYRB68C8",
        "outputId": "652671f1-d64d-4b65-de00-29ccc33c0d73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['intents'])\n",
            "<class 'list'>\n",
            "285\n",
            "dict_keys(['intent', 'text', 'responses', 'extension', 'context', 'entityType', 'entities'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intent': 'OrderRejection',\n",
              " 'text': ['No'],\n",
              " 'responses': ['order cancelled'],\n",
              " 'extension': {'function': '', 'entities': False, 'responses': []},\n",
              " 'context': {'in': '', 'out': '', 'clear': False},\n",
              " 'entityType': 'NA',\n",
              " 'entities': []}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "with open('intents.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(data.keys())\n",
        "print(type(data['intents']))\n",
        "print(len(data['intents']))\n",
        "print(data['intents'][0].keys())\n",
        "data['intents'][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhvzrrbG7Iga"
      },
      "outputs": [],
      "source": [
        "def clean(line):\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char.isalpha():\n",
        "            cleaned_line += char\n",
        "        else:\n",
        "            cleaned_line += ' '\n",
        "    cleaned_line = ' '.join(cleaned_line.split())\n",
        "    return cleaned_line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ersH_Q957LV8"
      },
      "outputs": [],
      "source": [
        "#list of intents\n",
        "intents = []\n",
        "unique_intents = []\n",
        "#all text data to create a corpus\n",
        "text_input= []\n",
        "#dictionary mapping intent with appropriate response\n",
        "response_for_intent = {}\n",
        "for intent in data['intents']:\n",
        "    #list of unique intents\n",
        "    if intent['intent'] not in unique_intents:\n",
        "        unique_intents.append(intent['intent'])\n",
        "    for text in intent['text']:\n",
        "        #cleaning is done before adding text to corpus\n",
        "        text_input.append(clean(text))\n",
        "        intents.append(intent['intent'])\n",
        "    if intent['intent'] not in response_for_intent:\n",
        "        response_for_intent[intent['intent']] = []\n",
        "    for response in intent['responses']:\n",
        "        response_for_intent[intent['intent']].append(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxqzckzR7Pad",
        "outputId": "8c10cd44-37fa-4ef1-afc0-47042acd642c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intent : DrinkSelection1\n",
            "Number of Intent: 285\n",
            "Sample Input: Make drink one\n",
            "Length of text_input: 285\n",
            "Sample Response:  ['Virgin Mojito selected. Preparing your refreshing drink!', \"You've chosen a Virgin Mojito. Let's mix it up!\", 'Virgin Mojito coming right up! Stay fresh.', 'Virgin Mojito selected. Preparing your refreshing drink!', \"You've chosen a Virgin Mojito. Let's mix it up!\", 'Virgin Mojito coming right up! Stay fresh.', 'Virgin Mojito selected. Preparing your refreshing drink!', \"You've chosen a Virgin Mojito. Let's mix it up!\", 'Virgin Mojito coming right up! Stay fresh.', 'Virgin Mojito selected. Preparing your refreshing drink!', \"You've chosen a Virgin Mojito. Let's mix it up!\", 'Virgin Mojito coming right up! Stay fresh.', 'Virgin Mojito selected. Preparing your refreshing drink!', \"You've chosen a Virgin Mojito. Let's mix it up!\", 'Virgin Mojito coming right up! Stay fresh.', 'Virgin Mojito selected. Preparing your refreshing drink!', \"You've chosen a Virgin Mojito. Let's mix it up!\", 'Virgin Mojito coming right up! Stay fresh.', 'Virgin Mojito selected. Preparing your refreshing drink!', \"You've chosen a Virgin Mojito. Let's mix it up!\", 'Virgin Mojito coming right up! Stay fresh.', 'Virgin Mojito selected. Preparing your refreshing drink!', \"You've chosen a Virgin Mojito. Let's mix it up!\", 'Virgin Mojito coming right up! Stay fresh.', 'Virgin Mojito selected. Preparing your refreshing drink!', \"You've chosen a Virgin Mojito. Let's mix it up!\", 'Virgin Mojito coming right up! Stay fresh.', 'Virgin Mojito selected. Preparing your refreshing drink!', \"You've chosen a Virgin Mojito. Let's mix it up!\", 'Virgin Mojito coming right up! Stay fresh.', 'Virgin Mojito selected. Preparing your refreshing drink!', \"You've chosen a Virgin Mojito. Let's mix it up!\", 'Virgin Mojito coming right up! Stay fresh.', 'Virgin Mojito selected. Preparing your refreshing drink!', \"You've chosen a Virgin Mojito. Let's mix it up!\", 'Virgin Mojito coming right up! Stay fresh.', 'Virgin Mojito selected. Preparing your refreshing drink!', \"You've chosen a Virgin Mojito. Let's mix it up!\", 'Virgin Mojito coming right up! Stay fresh.', 'Virgin Mojito selected. Preparing your refreshing drink!', \"You've chosen a Virgin Mojito. Let's mix it up!\", 'Virgin Mojito coming right up! Stay fresh.']\n"
          ]
        }
      ],
      "source": [
        "print(\"Intent :\",intents[0])\n",
        "print(\"Number of Intent:\",len(intents))\n",
        "print(\"Sample Input:\", text_input[0])\n",
        "print('Length of text_input:',len(text_input))\n",
        "print(\"Sample Response: \", response_for_intent[intents[0]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import pickle"
      ],
      "metadata": {
        "id": "D2-L17URkFgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpuErZ2C7Tk1",
        "outputId": "a212f94d-6c91-4ea2-edf8-228bbe4ee85e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Input Sequence: (285, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  3,  2, 12],\n",
              "       [ 0, 10,  2,  6, 12],\n",
              "       [ 0,  4,  5,  2, 12],\n",
              "       [ 7,  8,  3,  2, 12],\n",
              "       [ 0,  0,  2, 12,  9]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "tokenizer = Tokenizer(filters='',oov_token='<unk>')\n",
        "tokenizer.fit_on_texts(text_input)\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "sequences = tokenizer.texts_to_sequences(text_input)\n",
        "padded_sequences = pad_sequences(sequences, padding='pre')\n",
        "print('Shape of Input Sequence:',padded_sequences.shape)\n",
        "padded_sequences[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH1cbuz57qow",
        "outputId": "71686b0b-3c14-4c27-f1a1-0180bd82e040"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Intents : 25\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'DrinkSelection1',\n",
              " 1: 'DrinkSelection2',\n",
              " 2: 'DrinkSelection3',\n",
              " 3: 'DrinkSelection4',\n",
              " 4: 'DrinkSelection5',\n",
              " 5: 'DrinkSelection6',\n",
              " 6: 'DrinkSelection7',\n",
              " 7: 'DrinkSelection8',\n",
              " 8: 'DrinkSelection9',\n",
              " 9: 'DrinkSelection10',\n",
              " 10: 'DrinkSelection11',\n",
              " 11: 'DrinkSelection12',\n",
              " 12: 'DrinkSelection13',\n",
              " 13: 'DrinkSelection14',\n",
              " 14: 'DrinkSelection15',\n",
              " 15: 'DrinkSelection16',\n",
              " 16: 'DrinkSelection17',\n",
              " 17: 'DrinkSelection18',\n",
              " 18: 'DrinkSelection19',\n",
              " 19: 'DrinkSelection20',\n",
              " 20: 'High',\n",
              " 21: 'medium',\n",
              " 22: 'Low',\n",
              " 23: 'OrderConfirm',\n",
              " 24: 'OrderRejection'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "intent_to_index = {}\n",
        "categorical_target = []\n",
        "index = 0\n",
        "\n",
        "for intent in intents:\n",
        "    if intent not in intent_to_index:\n",
        "        intent_to_index[intent] = index\n",
        "        index += 1\n",
        "    categorical_target.append(intent_to_index[intent])\n",
        "\n",
        "num_classes = len(intent_to_index)\n",
        "print('Number of Intents :',num_classes)\n",
        "\n",
        "# Convert intent_to_index to index_to_intent\n",
        "index_to_intent = {index: intent for intent, index in intent_to_index.items()}\n",
        "index_to_intent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ka5m44Q7sgk",
        "outputId": "ca909cd9-b254-47de-e02a-8c7f6c014134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Ca (285, 25)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "categorical_vec = tf.keras.utils.to_categorical(categorical_target,\n",
        "                                                num_classes=num_classes)\n",
        "\n",
        "categorical_vec = categorical_vec.astype('int32')\n",
        "\n",
        "print('Shape of Ca',categorical_vec.shape)\n",
        "categorical_vec[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfmcXsUH7wfL",
        "outputId": "0496115b-88f8-4ae3-dde1-8c21c79f8dcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Dimension :25,\n",
            "Output Dimension :25\n"
          ]
        }
      ],
      "source": [
        "epochs=150\n",
        "embed_dim=300\n",
        "lstm_num=50\n",
        "output_dim=categorical_vec.shape[1]\n",
        "input_dim=len(unique_intents)\n",
        "print(\"Input Dimension :{},\\nOutput Dimension :{}\".format(input_dim,output_dim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Aae94wS72_t"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
        "                              output_dim=embed_dim,\n",
        "                              input_length=padded_sequences.shape[1]),  # Input shape specified here\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_num, dropout=0.1)),\n",
        "    tf.keras.layers.Dense(lstm_num, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(output_dim, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iGn77XHK54L"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
        "                              output_dim=embed_dim,\n",
        "                              input_length=padded_sequences.shape[1]),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_num, return_sequences=True, dropout=0.2)),\n",
        "    tf.keras.layers.LSTM(lstm_num, dropout=0.2),\n",
        "    tf.keras.layers.Dense(lstm_num, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(output_dim, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsVN5J5W8IkX",
        "outputId": "d203411a-510f-40a1-af6e-bf0ae52a2655"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78cc01cb63b0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model.fit(padded_sequences, categorical_vec, epochs=epochs, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "AgJT3kHEEBHh",
        "outputId": "00e84f76-afb9-411f-898c-d805226ffb97"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m300\u001b[0m)              │          \u001b[38;5;34m10,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │         \u001b[38;5;34m140,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m5,050\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                  │           \u001b[38;5;34m1,275\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">140,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m472,577\u001b[0m (1.80 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">472,577</span> (1.80 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m157,525\u001b[0m (615.33 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">157,525</span> (615.33 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m315,052\u001b[0m (1.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">315,052</span> (1.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMWuXdgx-o9z",
        "outputId": "7ee57fb2-fb8f-4e18-faa4-cc6ef13782f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - accuracy: 1.0000 - loss: 0.0397\n"
          ]
        }
      ],
      "source": [
        "test_text_inputs = [\"one\",\n",
        "                    \"three\",\n",
        "                    \"four\",\n",
        "                    \"five\",\n",
        "                    \"six\"]\n",
        "\n",
        "test_intents = [\"DrinkSelection1\",\n",
        "                \"DrinkSelection3\",\n",
        "                \"DrinkSelection4\",\n",
        "                \"DrinkSelection5\",\n",
        "                \"DrinkSelection6\"\n",
        "             ]\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_text_inputs)\n",
        "test_padded_sequences = pad_sequences(test_sequences,  padding='pre')\n",
        "test_labels = np.array([unique_intents.index(intent) for intent in test_intents])\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes)\n",
        "loss, accuracy = model.evaluate(test_padded_sequences, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CchAJzdk_HuC"
      },
      "outputs": [],
      "source": [
        "def response(sentence):\n",
        "    sent_tokens = []\n",
        "    # Split the input sentence into words\n",
        "    words = sentence.split()\n",
        "    # Convert words to their corresponding word indices\n",
        "    for word in words:\n",
        "        if word in tokenizer.word_index:\n",
        "            sent_tokens.append(tokenizer.word_index[word])\n",
        "        else:\n",
        "            # Handle unknown words\n",
        "            sent_tokens.append(tokenizer.word_index['<unk>'])\n",
        "    sent_tokens = tf.expand_dims(sent_tokens, 0)\n",
        "    #predict numerical category\n",
        "    pred = model(sent_tokens)\n",
        "    #category to intent\n",
        "    pred_class = np.argmax(pred.numpy(), axis=1)\n",
        "    # random response to that intent\n",
        "    return random.choice(\n",
        "        response_for_intent[index_to_intent[pred_class[0]]]), index_to_intent[pred_class[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ5RZpckLu7s"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def convert_digits_to_words(text):\n",
        "    # Dictionary of numbers to words (1 to 20)\n",
        "    number_words = {\n",
        "        '1': 'one',\n",
        "        '2': 'two',\n",
        "        '3': 'three',\n",
        "        '4': 'four',\n",
        "        '5': 'five',\n",
        "        '6': 'six',\n",
        "        '7': 'seven',\n",
        "        '8': 'eight',\n",
        "        '9': 'nine',\n",
        "        '10': 'ten',\n",
        "        '11': 'eleven',\n",
        "        '12': 'twelve',\n",
        "        '13': 'thirteen',\n",
        "        '14': 'fourteen',\n",
        "        '15': 'fifteen',\n",
        "        '16': 'sixteen',\n",
        "        '17': 'seventeen',\n",
        "        '18': 'eighteen',\n",
        "        '19': 'nineteen',\n",
        "        '20': 'twenty'\n",
        "    }\n",
        "\n",
        "    # Replace digits (from 1 to 20) with words\n",
        "    text = re.sub(r'\\b(?:1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20)\\b',\n",
        "                  lambda match: number_words[match.group(0)], text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "J9a5UKW5LyPN",
        "outputId": "e43b0b7d-c65c-41c9-be77-694ad7686a0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: Enter 'quit' to break the loop.\n",
            "You: i want drink 1\n",
            "Geek: Virgin Mojito coming right up! Stay fresh. -- TYPE: DrinkSelection1\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-b4c87005966a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'You: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "print(\"Note: Enter 'quit' to break the loop.\")\n",
        "\n",
        "\n",
        "\n",
        "while True:\n",
        "    query = input('You: ')\n",
        "\n",
        "    if query.lower() == 'quit':\n",
        "        break\n",
        "\n",
        "    # Apply digit conversion preprocessing before passing the query to the model\n",
        "    query = convert_digits_to_words(query)\n",
        "\n",
        "    bot_response, typ = response(query)  # Assuming response is your function for bot reply\n",
        "    print('Geek: {} -- TYPE: {}'.format(bot_response, typ))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "Wu1iISdB_LKh",
        "outputId": "c5d11e89-43bd-47cf-b421-3827abeba727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: Enter 'quit' to break the loop.\n",
            "You: 1\n",
            "Geek: Nojito selected. A mojito without the buzz! -- TYPE: DrinkSelection5\n",
            "\n",
            "You: i need drink number 1\n",
            "Geek: You've chosen Mango Mule. A delicious twist is coming. -- TYPE: DrinkSelection7\n",
            "\n",
            "You: i need drink number one\n",
            "Geek: You've chosen a Virgin Mojito. Let's mix it up! -- TYPE: DrinkSelection1\n",
            "\n",
            "You: i need drink number eleven\n",
            "Geek: You've chosen Arnold Palmer. The perfect balance of flavors. -- TYPE: DrinkSelection11\n",
            "\n",
            "You: i need drink number 11\n",
            "Geek: Watermelon Lemonade selected. A fruity twist on a classic! -- TYPE: DrinkSelection14\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-31022bfe48c8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Note: Enter 'quit' to break the loop.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'You: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "print(\"Note: Enter 'quit' to break the loop.\")\n",
        "while True:\n",
        "    query = input('You: ')\n",
        "    if query.lower() == 'quit':\n",
        "        break\n",
        "    bot_response, typ = response(query)\n",
        "    print('Geek: {} -- TYPE: {}'.format(bot_response, typ))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmdbblHFOA98",
        "outputId": "3122f58a-9191-4f29-a07d-de85814bbad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.save('intent_recognition_model_V1.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNdUQxIXUNv+V26eQ+/2Mnt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}